#+hugo_base_dir: ~/Desarrollo/algui91-hugo
#+hugo_auto_set_lastmod: t

#+seq_todo: TODO DRAFT DONE

#+startup: indent

#+options: H:6


#+macro: imageclick [[file:/img/$1][file:/img/$1]]
#+macro: user @[[https://github.com/$1][*$1*]]
#+macro: test-search Search the ~ox-hugo~ test site for [[https://ox-hugo.scripter.co/test/search/?q=$1]["$1"]] examples.
#+macro: guser [[https://www.github.com/$1][*@$1*]] from GitHub
#+macro: ruser [[https://www.reddit.com/user/$1][*/u/$1*]] from Reddit
#+macro: tuser [[https://www.twitter.com/$1][*@$1*]] from Twitter
#+macro: huser [[https://news.ycombinator.com/user?id=$1][*$1*]] from Hacker News
#+macro: ghlink [[https://github.com/$1][/$1/]]

# https://scripter.co/latex-in-html/
#+macro: latex @@html:<span class="latex">L<sup>a</sup>T<sub>e</sub>X</span>@@

# https://scripter.co/latex-in-html/
#+macro: latex @@html:<span class="latex">L<sup>a</sup>T<sub>e</sub>X</span>@@

#+author: alex

* Dev                                                                  :@dev:
** Arduino line follower                                           :arduino:
*** DONE Arduino Zumo Siguelineas Evita obstaculos :robótica:@how_to:@articulos:
CLOSED: [2018-09-16 Sun 18:42]
:PROPERTIES:
:EXPORT_DESCRIPTION: Proyecto Arduino con un Zumo que sigue líneas y evita obstáculos
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :mainclass dev
:EXPORT_FILE_NAME: arduino-line-follower-obstacles.md
:EXPORT_HUGO_URL: arduino-sigue-lineas-obstaculos
:END:
#+BEGIN_QUOTE
Este proyecto forma parte de un trabajo para la asignatura /Robótica Móvil y
Neurobótica/ del /Máster en Ciencia de Datos/ de la ETSIIT. Sus autores son
[[/author/cristina/][Cristina Heredia]] y [[/author/alex/][Alejandro Alcalde.]] El código está disponible en {{{ghlink(HerAlc/LineFollowerObstacles)}}}
#+END_QUOTE
El proyecto se compone de *dos partes*. La *primera* consiste en crear un robot
que siga un camino pre-establecido marcado con líneas, además, debe evitar
cualquier obstáculo que se encuentre en el camino. En caso de encontrarse con un
obstáculo, el robot se detiene unos segundos y avisa, si pasado un tiempo el
obstáculo sigue presente, el robot da media vuelta y sigue en camino contrario.
La *segunda parte* se trata de implementar este funcionamiento en el entorno
simulado Vrep.
**** Arduino
Para esta parte se ha implementado un Zumo capaz de conducir por sí mismo con las siguientes funcionalidades:

- Sigue Líneas
- Detección de obstáculos y toma de decisiones.
- Avisos sonoros a los obstáculos.

Para el sigue líneas se usan tres *sensores sigue  líneas* para detectar cambios de intensidad.

Antes de comenzar, el robot necesita calibrar el *giroscopio* y los sensores sigue líneas. Para ello hay que pulsar el botón =A= una vez, esto calibra el giroscopio. Pulsar el botón =A= una segunda vez calibra los sensores sigue líneas.

Cabe mencionar que se parte del ejemplo Sigue Líneas de Arduino, disponible en el IDE de Arduino, las modificaciones realizadas han sido las siguientes:

Se integra código del ejemplo =MazeSolver=, que hace uso del giroscopio, en concreto los ficheros =TurnSensor.h= y =TurnSensor.cpp=. Esto permite calibrar el giroscopio, el cual es necesario para conseguir que el robot de media vuelta e inicie el camino contrario si el obstáculo que encuentra en su camino no se retira en tres segundos.

Para la *detección de obstáculos* se hace uso de un sensor de proximidad. La distancia a la que se para el robot se fija al valor 6. Cuando el robot se detiene al encontrar un obstáculo, avisa con una melodía simple compuesta por nosotros y similar al *claxon* de un vehículo. Finalmente, cuando el robot espera más de tres segundos y el obstáculo sigue presente, avisa con otra melodía compuesta por nosotros e inicia al camino en sentido opuesto girando 180 grados.
***** Vídeo
#+BEGIN_EXPORT html
<iframe width="560" height="315"
src="https://www.youtube-nocookie.com/embed/UwPJgL0ix_8" frameborder="0"
allow="autoplay; encrypted-media" allowfullscreen></iframe>
#+END_EXPORT
**** VREP
Para el proyecto en VREP se ha implementado un robot *Sigue Líneas* que se detiene ante la presencia de un obstáculo. Si el obstáculo se retira durante la simulación, el robot sigue su camino. Si el obstáculo no se retira, el robot permanece sin moverse para evitar chocar con él.

Para seguir las líneas se ha adaptado el ejemplo de VREP /LineFollowerBubbleRob/ para hacerlo funcionar con Zumo, usando el modelo proporcionado en clase. La adaptación ha consistido en modificar el código de /BubbleRob/, que solo tiene dos motores, y hacerlo funcionar en el Zumo, con cuatro motores. Para ello se han tenido que ajustar parámetros de torque, peso etc de acuerdo al Zumo. También se desactivó el comportamiento cíclico de los motores.

Para evitar obstáculos se añade al robot un sensor de proximidad frontal, de forma similar al que se hizo en clase. Cuando el objeto se detecta a una distancia mínima pre-establecida, se detienen los motores del robot durante tres segundos. Transcurrido este tiempo, se vuelven a leer los datos del sensor de proximidad para comprobar si el objeto sigue presente o no. En caso de estar presente, el robot permanece parado, de lo contrario reanuda su marcha.

A continuación se muestra el código principal que controla el Zumo.

#+BEGIN_SRC lua
function sysCall_actuation()
    currTime = sim.getSimulationTime()
    result,distance=sim.readProximitySensor(noseSensor)

    if (result == 1 and distance < .25) then
        speed = 0
        if (objectDetected == false) then
            timeOjectDetected = sim.getSimulationTime()
            objectDetected = true
        end
        --sim.addStatusbarMessage(tostring(timeOjectDetected))
    end
    timeWaitingDetectedObject = currTime - timeOjectDetected
    sim.addStatusbarMessage(tostring(timeWaitingDetectedObject))
    -- After 3 seconds, check if continue foward or turn back
    if (timeWaitingDetectedObject > 3 ) then
        result,distance=sim.readProximitySensor(noseSensor)
        if (result == 0) then
            speed = -5
            timeOjectDetected = 0
            objectDetected = false
        end
    end

    -- read the line detection sensors:
    sensorReading={false,false,false}
    for i=1,3,1 do
        result,data=sim.readVisionSensor(floorSensorHandles[i])
        if (result>=0) then
            -- data[11] is the average of intensity of the image
            sensorReading[i]=(data[11]<0.3)
        end
    end

    rightV=speed
    leftV=speed

    if sensorReading[1] then
        leftV=0.03*speed
    end
    if sensorReading[3] then
        rightV=0.03*speed
    end
    -- When in forward mode, we simply move forward at the desired speed
    sim.setJointTargetVelocity(frontLeftMotor,leftV)
    sim.setJointTargetVelocity(frontRightMotor,rightV)
    sim.setJointTargetVelocity(rearLeftMotor,leftV)
    sim.setJointTargetVelocity(rearRightMotor,rightV)
end
#+END_SRC

En el código se lleva la cuenta del tiempo transcurrido desde la última vez que se detuvo el robot, para decidir cuando se debe hacer la siguiente lectura del sensor de proximidad. La distancia máxima de detección de objetos se fija a 0.25.

Para el funcionamiento del sigue líneas se emplean tres sensores sigue líneas (Izquierdo, central y derecho), ubicados en la parte delantera del Robot. Dichos sensores se colocan con el eje z hacia abajo. De todos los datos proporcionados por los sensores se usa la intensidad media de la imagen para ajustar la velocidad de los motores. Aunque se incorporó un sensor central, no ha sido necesario su uso, ya que el robot sigue las líneas bien con los otros dos.

En los ficheros adjuntos se proporcionan vídeos de ejemplo de ambas prácticas.
***** Vídeo VREP
#+BEGIN_EXPORT html
<iframe width="560" height="315"
src="https://www.youtube-nocookie.com/embed/dixjPmbJ1Ts" frameborder="0"
allow="autoplay; encrypted-media" allowfullscreen></iframe>
#+END_EXPORT
*** DONE Arduino Zumo Line Follower and Obstacle avoider
CLOSED: [2018-09-16 Sun 18:42]
:PROPERTIES:
:EXPORT_DESCRIPTION: Arduino project of a Zumo 32U4 robot line follower and obstacle avoider
:EXPORT_FILE_NAME: arduino-line-follower-obstacles.en.md
:EXPORT_HUGO_URL: /en/arduino-line-follower-obstacles
:END:
#+BEGIN_QUOTE
This project is a job assignment for a course on Robotics and Neurobotics at the
Master on Data Science of the University of Granada. Its authors are [[/en/author/cristina][Cristina
Heredia]] and [[/en/author/alex][Alejandro Alcalde]].
#+END_QUOTE
This project is composed of *two parts*. *First part* consist on program a robot
(Zumo 32U4) that follows a determined path marked by black lines. In addition it
must avoid any obstacle it encounters. In case of being in front of an obstacle,
the robot stops a few seconds and beeps, if time passes and the obstacle is
still on the path, the robots will turn around and will continue in the opposite
direction. *Second part* is about implementing this behavior in VREP simulator.
Lets begin.
**** Arduino
In this section the Zumo 32U4 is capable of drive by itself with the following
functionalities:

- Line follower.
- Object detection and avoidance.
- Alert sounds to the obstacles.

For the line follower three *line sensors* are used to detect the path.

Before starting, the robot needs to calibrate its *gyroscope* and line sensors.
Pressing button =A= once will calibrate the gyroscope, pressing it a second time
will calibrate line sensors.

It is worth mentioning we have started with the Line follower example from
Arduino IDE. The following code modifications has been made:

We have integrated code from =MazeSolver=, which makes uses of the gyroscope, in
particular, files =TurnSensor.h= and =TurnSensor.cpp=. This allow us to
calibrate the gyroscope.

To *detect obstacles* a proximity sensor is used. The distance between the robot
and the obstacle is set to 6. When the robot sees and obstacle and stops, it
plays a sound similar to a *car's horn*. Finally, when the robot waits for more
than three seconds and the obstacle is still there, it plays another sound and
turns around. Next we show a video:
***** Video
#+BEGIN_EXPORT html
<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/UwPJgL0ix_8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
#+END_EXPORT

**** VREP
The VREP project has implemented a *line follower* robot which stops in front of
an obstacle. If the obstacle is removed during the simulation the robot will
continue his path, otherwise it will stay still.

In this implementation, we have used the code from /LineFollowerBubbleRob/ from
the VREP examples. The code is shown below:

#+BEGIN_SRC lua
function sysCall_actuation()
    currTime = sim.getSimulationTime()
    result,distance=sim.readProximitySensor(noseSensor)

    if (result == 1 and distance < .25) then
        speed = 0
        if (objectDetected == false) then
            timeOjectDetected = sim.getSimulationTime()
            objectDetected = true
        end
        --sim.addStatusbarMessage(tostring(timeOjectDetected))
    end
    timeWaitingDetectedObject = currTime - timeOjectDetected
    sim.addStatusbarMessage(tostring(timeWaitingDetectedObject))
    -- After 3 seconds, check if continue foward or turn back
    if (timeWaitingDetectedObject > 3 ) then
        result,distance=sim.readProximitySensor(noseSensor)
        if (result == 0) then
            speed = -5
            timeOjectDetected = 0
            objectDetected = false
        end
    end

    -- read the line detection sensors:
    sensorReading={false,false,false}
    for i=1,3,1 do
        result,data=sim.readVisionSensor(floorSensorHandles[i])
        if (result>=0) then
            -- data[11] is the average of intensity of the image
            sensorReading[i]=(data[11]<0.3)
        end
    end

    rightV=speed
    leftV=speed

    if sensorReading[1] then
        leftV=0.03*speed
    end
    if sensorReading[3] then
        rightV=0.03*speed
    end
    -- When in forward mode, we simply move forward at the desired speed
    sim.setJointTargetVelocity(frontLeftMotor,leftV)
    sim.setJointTargetVelocity(frontRightMotor,rightV)
    sim.setJointTargetVelocity(rearLeftMotor,leftV)
    sim.setJointTargetVelocity(rearRightMotor,rightV)
end
#+END_SRC

What this code does is keep track of the time passed since the robot first
stops in order to know when to check the proximity sensor again.
***** VREP Video
#+BEGIN_EXPORT html
<iframe width="560" height="315"
src="https://www.youtube-nocookie.com/embed/dixjPmbJ1Ts" frameborder="0"
allow="autoplay; encrypted-media" allowfullscreen></iframe>
#+END_EXPORT
Hope you find it interesting!
* Datascience                                                  :@datascience:
** Social Media Mining                               :community:data_mininig:
*** DRAFT Análisis y Visualización Básica de una Red Social de Twitter con Gephi
     :PROPERTIES:
     :EXPORT_DESCRIPTION: En este artículo se muestra un análisis de la red social de @elbaulp en Twitter.
     :EXPORT_HUGO_CUSTOM_FRONT_MATTER: :mainclass datascience
     :EXPORT_FILE_NAME: social-mining-gephi.md
     :EXPORT_HUGO_URL: social-mining-gephi
     :END:
#+BEGIN_QUOTE
Este artículo es el resultado de un ejercicio para la asignatura /Minería de
Medios Sociales/ en el máster en Ciencia de Datos de la UGR
#+END_QUOTE

**** Análisis de la red
Esta red contiene un subconjunto de los seguidores de la cuenta [[https://twitter.com/ElBaulP][@elbaulp]] de Twitter, ya que por limitaciones de la API la descarga de la red de hasta segundo grado de conexión tardaba mucho.

El objetivo de este análisis es identificar a los actores más influyentes, que hacen de puente entre comunidades para poder expandir el número de seguidores de @ElbaulP

***** Grado medio

- N = 2132 nodos.
- L = 6643 enlaces
- Densidad = 0.001
- Grado medio = 3.116, lo cual quiere decir que cada nodo de la red está conectado con otros 3 en media.

A continuación se muestran las gráficas de densidades de los grados.

[[/img/avgdegree/degree-distribution.png]]

En cuanto a grados totales, hay cuatro nodos que destacan, con un grado de mayor a 120. El nodo con mayor grado es de 161. Estos nodos se corresponden con /hubs/. La distribución de grados indica que se cumple la propiedad libre de escala. Muy pocos con muchas conexiones, y muchos con pocas conexiones.

#+CAPTION: A black cat stalking a spider
#+ATTR_HTML: :alt cat/spider image :title Action! :align right :width 600 :height 400
{{{imageclick(avgdegree/indegree-distribution.png)}}}

[[file:/img/avgdegree/indegree-distribution.png]]

Los nodos con mayor grado de entrada (Con mayor número de seguidores) tienen 120 y 160 seguidores, respectivamente.

[[file:/img/avgdegree/outdegree-distribution.png]]

Pasa absolutamente lo mismo para los grados de entrada y salida, en el caso de Twitter esto indica seguidores y seguidos. El usuario con más amigos tiene unos 99 amigos.

***** Diámetro

El diámetro de la red es de 13. Este valor representa la máxima distancia existente entre dos nodos en toda la red. La distancia media es de 4.5.

El histograma de distancias es el siguiente:

[[file:/img/diameter/Closeness-Centrality-Distribution.png]]

El diagrama de cercanía nos indica que hay bastantes nodos muy alejados del centro (entorno a unos 90). Otros, por contra, están muy situados en el centro de la red (unos 85). El resto de nodos se situan a los alrededores del centro de la red.

***** Conectividad
Se tienen 845 componentes conexas, la componente gigante agrupa 1261 nodos. El coeficiente de clustering medio es 0.068. En este caso es bajo, ya que la cuenta de twitter es de un blog, en lugar de una cuenta personal. El histograma CC es el siguiente:

[[file:/img/gephi/clustering.png]]

Lo cual indica que en regiones poco pobladas el coeficiente de clustering es muy alto, ya que los nodos están más conectados entre ellos localmente. Por ello destaca un punto muy alto al principio de la gráfica.

**** Centralidad de los actores

Los cinco primeros actores para las siguientes medidas son:

| Centralidad de Grado | Intermediación        | Cercanía           | Vector propio          |
|----------------------+-----------------------+--------------------+------------------------|
|-
| <c>                  | <c>                   | <c>                | <c>                    |
| nixcraft: 161        | rootjaeger: 0.048     | programador4web: 1 | Makova_: 1             |
| Makova\_: 151        | podcastlinux: 0.048   | KevinhoMorales: 1  | psicobyte_: 0.966      |
| cenatic: 132         | Linuxneitor: 0.043    | elrne: 1           | Terceranexus6: 0.908   |
| Terceranexus6: 129   | Makova\_: 0.039       | Mrcoo16: 1         | NuriaStatgirl: 0.796   |
| LignuxSocial: 121    | Wdesarrollador: 0.038 | RodriKing14: 1     | Inter_ferencias: 0.780  |

En cuanto a la *centralidad de grado*, no se tiene muy en cuenta, aunque refleja el número de conexiones de un actor, no tiene en cuenta la estructura global de la red.

Una medida bastante importante es la *intermediación*, estos actores hacen de puente entre otras regiones de la red. Por lo cual pueden conectar distintas comunidades entre sí. En el caso que nos ocupa (Twitter), si conseguimos que uno de estos actores nos mencione o nos haga RT, nuestro tweet podrá llegar a otro tipo de usuarios que quizá estén interesados en nuestras ideas.

La *cercanía* mide cómo de cerca está un actor del centro de la red. En este caso no nos sirve de mucho, ya que todos los nodos tienen la misma medida.

Por último, la *centralidad de vector propio* es una medida recursiva que asigna importancia a un nodo en función de la importancia de sus vecinos. Es decir, tiene en cuenta la calidad de las conexiones, en lugar de la cantidad. El primer actor tiene un valor de esta medida de 1, lo cual indica que es el nodo más importante y con el mayor número de conexiones importantes. Luego es un actor a tener en cuenta en la red.


**** Detección de comunidades
Para la detección de comunidades se ha usado un factor de resolución de 1.99 para obtener un total de 5 comunidades. Se ha elegido este valor de resolución debido a que valores inferiores resultaban en un mayor número de comunidades, pero muchas de ellas formadas por dos nodos. El valor para la modularidad es de un 0.436, lo cual es un buen valor.

La proporción de nodos en cada comunidad es la siguiente:

- 40.85%
- 21.39%
- 17.5%
- 10.98%
- 9.15%
- 0.14%

La distribución de modularidad se observa en la siguiente imagen:

[[file:/img/mod/communities-size-distribution.png]]

Todas tienen un tamaño razonable salvo una, demasiado pequeña.

La siguiente imagen muestra el grafo coloreado en función de a qué comunidad pertenece cada nodo:

[[file:/img/gephi/comunities.png]]

Analizando la red, se puede apreciar que la comunidad de arriba (Azul celeste) pertenece a nodos relacionados con la ETSIIT. Algunos miembros de esta comunidad hacen de puente (Son nodos con mucha intermediación) con otras comunidades. Por ejemplo, Makova_ y Linuxneitor hacen de puente con la comunidad morada, esta comunidad está más relacionada con usuarios de Linux y blogs de Linux. NataliaDiazRodrz hace de puente de la comunidad de la ETSIIT con la comunidad verde, más relacionada con la temática de Ciencia de Datos. Esto tiene sentido, ya que NataliaDiazRodrz estudió en la ETSIIT y trabaja en Ciencia de Datos, concretamente en temas de NLP. La comunidad Amarilla está relacionada con programación.

**** Gráficos adicionales

En la siguiente gráfica se muestra la red dispuesta con los colores en función del valor del vector propio, y el tamaño de los nodos como la intermediación:

[[file:/img/gephi/color-eige-size-betwenn.png]]

En la siguiente figura se muestra a la inversa, color la intermediación, tamaño el vector propio:

[[file:/img/gephi/color-betwenn-size-eigen.png]]

Considero que las medidas más importantes son el valor de vector propio y la intermediación, la siguiente gráfica muestra cómo están relacionadas entre ellas. A mayor valor para ambas mejor, más importante es el nodo:

[[file:/img/gephi/eigenvsbt.png]]

*** DRAFT Análisis y Visualización Básica de una Red Social de Twitter con Gephi EN
* Footnotes
* COMMENT Local Variables                                           :ARCHIVE:
# Local Variables:
# fill-column: 80
# eval: (auto-fill-mode 1)
# eval: (add-hook 'after-save-hook #'org-hugo-export-wim-to-md-after-save :append :local)
# org-hugo-footer: "\n\n[//]: # \"Exported with love from a post written in Org mode\"\n[//]: # \"- https://github.com/kaushalmodi/ox-hugo\""
# End:
